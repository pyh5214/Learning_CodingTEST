최종프로젝트

챗봇

주제선정(주제발표)
시나리오
이론을 학습하되 구현에 집중

웹서비스

NLP
GPT2

깃허브,슬랙 협업툴 고려

데이터웨어하우스(db쪽 구현에 여쭤볼게 많을듯)

용어질문
스탠포드 강좌(ai) => 이론, 블로그 참고

취업

상용화된 기술

데이터분석하는 업체를 찾아보기
코어기술

자바개발(자바수업, 클래스)
웹개발

아카이빙

텍스트 요약=> 음성출력, 점자
웹소설 => 소설트렌드, 댓글 감성, 소설추천
회의 키워드 추출 => 키워드 관련 트렌드 정보 추가
감성일기 => 심리평가, 마케팅
데일리 관심정보 및 필요정보 전달 => 노년층 대화봇
노년층 => 상담시스템
직원교육 => 메뉴얼화
서술형 답변 => 서술형 채점 
인터넷 방송, 라이브 커머스 => 악성댓글 차단
품질재단챗봇

감정분석
번역

요약

맥주소
인공지능
네이버(클로바)와 카카오
최적화 경쟁
학습데이터 생성(open cv 등), 증폭

NLP => 분류 (다음단어의 클래스를 분류하는 모델)

에너지 낭비
데이터 효율성

ai : 인풋,아웃풋 => 프로그램


텍스트마이닝, 인덱싱
다차원 벡터, 워드 임베딩(*)
감정분석 => 단어가 가진 차원을 줄이는 작업
인풋은 다차원을 => 아웃풋은 저자원으로 나오게 하는 목적

캡셔닝 => 이미지 처리 + NLP 처리
하나의 단어로 GAN => NLP처리 + 이미지 처리 => 여러가지 이미지가 나옴(단어가 더 다차원적이라는 점을 보임)


NLP
트랜스포머
RNN(백워드에 시간(비용)이 많이 소요)
LSTM(더 많은 시간이 소요)
GRU(LSTM의 복잡성을 감소)

NLP 구조
encoder 인식해주는 역할(귀)
임베딩
decoder 말로 표현해주는 역할(입) => 감정분석(분류는 MLP만으로 가능), generator
STT(speech to text)

어텐션 메커니즘
encoder
attention
decoder
=> 번역부분에 획기적인 발전

구글 Transformer
attention 에만 집중
병렬처리가 가능해짐
attenion is all you need
=> BERT

Transformer의 등장
BERT
transformer가 인코더만 있음

GPT
transformer가 디코더만 있음

BART
BERT + GPT를 결합
=> 요약에 많이 쓰임, 단 네트워크가 커져버림


NLP task
번역
분류(감정, OOP(고유명사, 품사 등))
extraction
Generation(기사만들기, 에세이쓰기, 요약도 포함)

NLP, 모달
text => 음성
text => 이미지

멀티모달

동영상 => 네이버 하이라이트 요약, 영화 트레일러

챗봇
GPT-2 => 의도분석(분류), 자연대화 + 의도분석(의도분석을 수행하며 자연대화 시나리오를 구성해감)
GPT-3

사투리
네트워크상에 다 학습이 되어있다보니, 개인정보마저 학습되어있을 수 있다.(개인정보를 특정 못짓게 하는 보안 처리)
나무위키 학습 => b급 모델
신조어 딥러닝


다차원 => 차원 리덕션
피처엔지니어링 => ai 네트워크가 직접 추출해냄


분류, bert
https://papersearch.net/thesis/article.asp?key=3860750
https://koasas.kaist.ac.kr/handle/10203/290488
사회적 가치
특수교육
어문, 발달장애 발음 => 워드로 표현

가짜뉴스


맥주, 해외리뷰 => 맥주리뷰

오늘저녁 뭐에요

전문용어 -> 학습이 어려움
노인, 장애인 -> 접근이 어려움, 그부분을 해결하기 위한 고민도 유의미할것

챗봇 시나리오

허깅페이스 - 메타 - 파이토치기반

